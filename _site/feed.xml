<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Polyphant</title>
    <description>Technology, Astronomy and other random noise, from an Astrophysicist in London
</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 18 Jan 2016 11:22:05 +0000</pubDate>
    <lastBuildDate>Mon, 18 Jan 2016 11:22:05 +0000</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>Top books 2015</title>
        <description>&lt;p&gt;I read a lot in 2015, so to round it all off here’s a selection of some of the best books I got through, in no particular order. None of them were actually released in 2015, so if you’re looking for the latest best sellers you’re going to have to wait for me to get through the last 30 centuries of human literature first. Which could take a little time. Science fiction features heavily, so if you’re mortally afraid of dystopian futures, look away quick.&lt;/p&gt;

&lt;h2 id=&quot;a-hrefhttpswwwgoodreadscombookshow826097neuromancer-targetblankneuromancer-william-gibsona&quot;&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/826097.Neuromancer&quot; target=&quot;blank&quot;&gt;Neuromancer, William Gibson&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This was my first introduction to the genre of cyberpunk, and I’m now hooked. Neuromancer single handedly invented the genre, and many of its most identifiable concepts, such as cyberspace, the matrix and hacker culture, were introduced here. The most outstanding thing is that this was Gibson’s &lt;em&gt;first novel&lt;/em&gt;, written on a &lt;em&gt;typewriter&lt;/em&gt; in the early 80’s before the internet was even a twinkle in Tim Berners-Lee’s eye. The writing is thick and fast, rich with slang and jargon, building a believable near future world where individuals struggle to survive amidst the jostling of mega corporations. I’ve since gone on to read parts 2 and 3 of the trilogy, but Neuromancer stands out for its originality. I can’t recommend it enough.&lt;/p&gt;

&lt;h2 id=&quot;a-hrefhttpswwwgoodreadscombookshow1239196fortressmalta-targetblankfortress-malta-james-hollanda&quot;&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/1239196.Fortress_Malta&quot; target=&quot;blank&quot;&gt;Fortress Malta, James Holland&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My late Nana grew up in Malta through the Second World War, and experienced first hand the destruction of her home country by German and Italian aerial bombardment, as well as the hunger and malnutrition that accompanied the siege. This was therefore an illuminating but difficult book to read, more so due to Holland’s approach, which told the story through the eyes of a multitude of characters on the ground and in the air above the skies of Malta. Definitely recommended for those interested in the lesser known battles of WWII, but also a rewarding read for all due to the manner in which Holland reveals the heartbreaking human side of the conflict.&lt;/p&gt;

&lt;h2 id=&quot;a-hrefhttpswwwgoodreadscombookshow7046300-the-forever-war-targetblank-the-forever-war-joe-haldemana&quot;&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/7046300-the-forever-war&quot; target=&quot;blank&quot;&gt; The Forever War, Joe Haldeman&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I haven’t read any other military science fiction, but I’m inclined to believe in this books reputation for being the best of its surprisingly populated subgenre. Haldeman, a Vietnam war veteran, uses the concept of time dilation to build a frightening future reality, where those men and women sent to the front lines of an interstellar war return to earth decades, if not hundreds of years in the planets future. The sense of cultural isolation is an obvious reflection of Haldeman’s experiences coming back from Vietnam.&lt;/p&gt;

&lt;h2 id=&quot;a-hrefhttpswwwgoodreadscombookshow294477foundation-targetblank-foundation-isaac-asimova&quot;&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/294477.Foundation&quot; target=&quot;blank&quot;&gt; Foundation, Isaac Asimov&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Reading a supposed ‘classic’ is always hazardous; the anticipation often leads to disappointment, or your initial expectations can be far from the mark. &lt;em&gt;Foundation&lt;/em&gt; was special, in that it was almost exactly what I expected, yet still blew me away. Asimov’s soft sci-fi style is not to everyones taste, but I really enjoyed the allegorical storylines, and the &lt;em&gt;Psychohistory&lt;/em&gt; invention, where human history can be predicted millenia in to the future through an understanding of human psychology on population scales. Parts 2 and 3 of the trilogy follow the same formula but never tire, showing the mileage of such a simple plot device.&lt;/p&gt;

&lt;h2 id=&quot;a-hrefhttpswwwgoodreadscombookshow107007theleagueofextraordinarygentlemenvol2-targetblank-league-of-extraordinary-gentlemen-vol-ii-alan-moore--kevin-oneilla&quot;&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/107007.The_League_of_Extraordinary_Gentlemen_Vol_2&quot; target=&quot;blank&quot;&gt; League of Extraordinary Gentlemen Vol. II, Alan Moore &amp;amp; Kevin O’Neill&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My favourite graphic novel I read last year, by one of my favourite graphic novelist’s in Alan Moore. The fantasy steampunk world created in the first volume is the scene for an alien invasion from Mars, inspired by H.G. Wells &lt;em&gt;War of the Worlds&lt;/em&gt;. My personal highlight is the first scene, where the cause of the Martian invasion is revealed to be due to a war on the surface of the red planet, from which the visitors are fleeing; the purposefully dated view of the conditions and creatures on the red planet reminded me of a short story, &lt;a href=&quot;https://www.goodreads.com/book/show/19300931-a-martian-odyssey&quot; target=&quot;blank&quot;&gt;A Martian Odyssey&lt;/a&gt;, by Stanley G. Weinbaum. Kevin O’Neill’s illustrations are fantastic; on reading some of the latter sequels, which falter on both the illustration and story front (Moore’s apparent disdain for women is becoming more prominent with age), I have come to appreciate O’Neill’s drawing style even more.&lt;/p&gt;

&lt;h2 id=&quot;a-hrefhttpswwwgoodreadscombookshow12455877-store-of-the-worlds-targetblank-store-of-the-worlds-robert-sheckleya&quot;&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/12455877-store-of-the-worlds&quot; target=&quot;blank&quot;&gt; Store of the Worlds, Robert Sheckley&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Robert Sheckley wrote short, fun and challenging science fiction; this is a collection of some of his best, from the genres heyday during the 60s and 70s. Throughout each story runs a thinly veiled current of dark humour and fatalism, which is right up my street. I’ve read a few science fiction short stories in 2015 but this collection stood out for its originality, often compromising on realism but never on imagination and fun.&lt;/p&gt;

&lt;h2 id=&quot;a-hrefhttpswwwgoodreadscombookshow1434257rising44-targetblank-rising-44-norman-daviesa&quot;&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/1434257.Rising_44&quot; target=&quot;blank&quot;&gt; Rising ‘44, Norman Davies&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I’ve already written a post on the Warsaw Rising, and a &lt;a href=&quot;/2015/11/15/orwell-warsaw.html&quot; target=&quot;blank&quot;&gt;renowned British authors take on it&lt;/a&gt;. It was inspired by this book, by my favourite historical author, which tells the tragic story of the Warsaw rising of 1944 (not to be mistaken with the Jewish Ghetto uprising earlier in the war). Davies is an ardent Pola-phile, having written the English language bible on Polish history and culture, God’s playground, making him suitably equipped to tackle one of the darkest hours in the countries history. The narrative is interspersed with writings from those on the ground, from both sides of the front line, which brings home the horror and destruction of the annihilation of one of Europe’s oldest and most vibrant cities. But it is Davies quietly directed rage towards those who oversaw, or rather overlooked, the calamity that leaves a lasting memory.&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Jan 2016 00:00:00 +0000</pubDate>
        <link>/2016/01/06/favourite-books-2015.html</link>
        <guid isPermaLink="true">/2016/01/06/favourite-books-2015.html</guid>
        
        <category>Books</category>
        
        
      </item>
    
      <item>
        <title>My First Astrobite</title>
        <description>&lt;p&gt;During my undergraduate I often read a site called Astrobites, which aims to bring front line research in Astronomy and Astrophysics to undergraduates via short, accessible articles written by graduate students. When I started my Ph.D I noticed that they were advertising for new writers and promptly applied. As part of the application I wrote a post about the EAGLE simulation, which I’ve started working on . I was fortunate enough to be accepted, and immediately given the date for my first post: Christmas Day. After some feedback from other Astrobite editors, and a little frantic Christmas Eve editing, I managed to publish it on time. It’s about an observational paper that came out this summer that claims to have glimpsed the light from the &lt;a href=&quot;http://arxiv.org/abs/1504.01734&quot; target=&quot;_blank&quot;&gt;first generation of stars&lt;/a&gt;. I’m admittedly pretty proud of it; I didn’t even consider the possibility of contributing to this site when doing my undergraduate. I actually ended up learning a lot too; it’s interesting how much extra attention you pay when you are responsible for teaching others (or just afraid of being called out).&lt;/p&gt;

&lt;p&gt;You can read the post &lt;a href=&quot;http://astrobites.org/2015/12/25/observational-evidence-for-the-first-generation-of-stars/&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;. The image below is of the galaxy CR7, the subject of the paper.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/cr7.jpg&quot; data-lightbox=&quot;lightbox-img&quot; data-title=&quot;CR7&quot;&gt;
  &lt;img src=&quot;/images/cr7.jpg&quot; title=&quot;CR7&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 26 Dec 2015 00:00:00 +0000</pubDate>
        <link>/2015/12/26/first-astrobite.html</link>
        <guid isPermaLink="true">/2015/12/26/first-astrobite.html</guid>
        
        <category>Physics</category>
        
        
      </item>
    
      <item>
        <title>Meeting the F &amp; W in NFW</title>
        <description>&lt;p&gt;I’ve just got back from a tiring but enjoyable few days in Leiden, attending my first ever &lt;a href=&quot;http://virgo.dur.ac.uk/about.php&quot;&gt;Virgo consortium&lt;/a&gt; meeting. Virgo was founded in the UK in 1994, but is now an international collaboration of scientists working on cosmological simulations. One of the founding members is now my primary supervisor, Peter Thomas.&lt;/p&gt;

&lt;p&gt;A couple of other founding members were in attendance, two of which could be considered celebrities in the astrophysics community due to a mathematical profile they formalised that bears their name. Carlos Frenk and Simon White, working with Julio Navarro, penned the Navarro-Frenk-White (NFW) profile in the mid 90s, and it has since gone on to become a standard for describing the density distribution of dark matter in cosmological halos. The paper that introduced it has gone on to garner nearly 4000 citations, &lt;a href=&quot;http://adsabs.harvard.edu/abs/1996ApJ...462..563N&quot;&gt;according to ADS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/nfw-history.gif&quot; data-lightbox=&quot;bilevel-partition&quot; data-title=&quot;Citation history for &#39;The Structure of Cold Dark Matter Halos&#39;, Navarro et al.&quot;&gt;
  &lt;img src=&quot;/images/nfw-history.gif&quot; title=&quot;Citation history for &#39;The Structure of Cold Dark Matter Halos&#39;, Navarro et al.&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Citation history for &lt;a href=&quot;http://adsabs.harvard.edu/abs/1996ApJ...462..563N&quot; target=&quot;blank&quot;&gt;&#39;The Structure of Cold Dark Matter Halos&#39;&lt;/a&gt;, Navarro et al.&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We can’t detect dark matter directly, so its presence must be inferred from its gravitational influence on baryonic matter. Inferring the exact distribution of dark matter in clusters of galaxies purely from the baryonic matter is challenging. The NFW profile was instead motivated and tuned to evidence from simulations of collisionless dark matter.&lt;/p&gt;

&lt;p&gt;They argue that there is a ‘universal’ profile for dark matter halos that spans four orders of magnitude of halo mass, from galaxy halos to entire clusters. This assertion is still contentious; other authors either find different forms of the profile, or that it varies with environment.&lt;/p&gt;

&lt;p&gt;The profile is also in tension with observations; the NFW profile suggests a central ‘cusp’ to the dark matter distribution, whereas observations suggest that dark matter haloes have shallower cores. This became known as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cuspy_halo_problem&quot; target=&quot;blank&quot;&gt;Cusp-Core controversy&lt;/a&gt;, and is still unresolved today.&lt;/p&gt;

&lt;p&gt;At the end of the meeting we discussed some interesting projects, some of which I’m hoping to get involved in from the new year; will keep you posted, all 3 of you dear readers.&lt;/p&gt;
</description>
        <pubDate>Sat, 19 Dec 2015 00:00:00 +0000</pubDate>
        <link>/2015/12/19/nfw-profile.html</link>
        <guid isPermaLink="true">/2015/12/19/nfw-profile.html</guid>
        
        <category>Physics</category>
        
        
      </item>
    
      <item>
        <title>Lord Kelvin and the age of the earth</title>
        <description>&lt;p&gt;The story of how scientists revealed the age of the earth is a remarkable one; at the beginning of the nineteenth century many still believed that the earth had been around forever, but by the 1920s evidence from fields as diverse as geology and biology had been united, and the definitive source of the Sun’s heat discovered. Perhaps what makes the story even more fascinating are the egos and personalities that shaped it, and none more so than that of William Thomson, aka Lord Kelvin.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/Lord_Kelvin_photograph.jpg&quot; data-lightbox=&quot;bilevel-partition&quot; data-title=&quot;Lord Kelvin&quot;&gt;
  &lt;img class=&quot;small&quot; src=&quot;/images/Lord_Kelvin_photograph.jpg&quot; title=&quot;Lord Kelvin&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Lord Kelvin was arguably the most eminent scientist of his time, famous today for the temperature scale that bears his name. But it was his work on thermodynamics that led him to ponder the question of the age of the earth. He saw an opportunity to apply the recently formulated laws of thermodynamics to the problem, in particular the first law, which states:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;The total energy of an isolated system is constant; energy can be transformed from one form to another, but cannot be created or destroyed&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is the principle of conservation of energy.&lt;/p&gt;

&lt;p&gt;Kelvin sought to apply this principle to calculate the age of the Sun; he held the view that the Earth must have been formed after the Sun, and so by limiting the age of the Sun he could imply upper limits on the age of the Earth.&lt;/p&gt;

&lt;p&gt;The Sun shines, and pretty brightly at that, so in assuming the principle of conservation of energy we imply that the Sun must have a source for this radiated energy. Kelvin’s theory for the source of this energy was &lt;em&gt;gravitational contraction&lt;/em&gt;; when a body contracts under its own gravity it releases energy, and according to Kelvin it was this energy that powered the Sun.&lt;/p&gt;

&lt;p&gt;We can calculate how much energy the Sun could possibly radiate if it collapsed from its current state with a little sixth form math and some Newtonian Mechanics.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; If you are allergic to Maths, feel free to skip the next bit. You don’t need it to follow the story, but I’d certainly recommend running through it if you can; it’s a beautiful, if flawed, argument!&lt;/p&gt;

&lt;p&gt;We first define the &lt;a href=&quot;https://en.wikipedia.org/wiki/Potential_energy#Gravitational_potential_energy&quot;&gt;gravitational potential energy&lt;/a&gt;, $\Omega$, from Newtonian mechanics, as,&lt;/p&gt;

&lt;center&gt;
$$\Omega = - \frac{Gm\_{1}m\_{2}}{r}$$
&lt;/center&gt;

&lt;p&gt;where $G$ is the gravitational constant, and $m_1$ and $m_2$ are two masses whose centres of gravity are separated by a distance $r$.&lt;/p&gt;

&lt;p&gt;To apply this to the Sun, and calculate its total gravitational potential energy, we first model it as a series of concentric shells, each of radius $dr$.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/concentric.jpg&quot; data-lightbox=&quot;bilevel-partition&quot; data-title=&quot;Concentric shells&quot;&gt;
  &lt;img class=&quot;small&quot; src=&quot;/images/concentric.jpg&quot; title=&quot;Concentric shells&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Concentric shells at radius $r$, width $dr$.&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;In the above definition, for a single shell at radius $r$, $m_1$ is the mass of the star within radius $r$, and $m_2$ is the mass of the shell itself. We then integrate between 0 and $R$, the radius of the Sun, to add up the contributions from all of the shells, giving the total gravitational potential energy of the entire star.&lt;/p&gt;

&lt;center&gt;
$$\Omega = -G \int_{0}^{R} \frac{m(r) 4 \pi r^{2} \rho}{r} dr$$
&lt;/center&gt;

&lt;p&gt;Here, $m(r)$ is the mass within radius $r$, and $4 \pi r^{2} \rho dr$ is the mass of the shell. We are assuming that the Sun has uniform density, which is not the case but sufficient for such a back of the envelope calculation; Kelvin made the very same assumption when making his argument.&lt;/p&gt;

&lt;p&gt;Now, rewrite $m(r)$ in terms of $r$ and $\rho$ to give&lt;/p&gt;

&lt;center&gt;
$$\Omega = -G \int_{0}^{R} \frac{4 \pi r^{3} 4 \pi r^{2} \rho}{3r} dr$$
&lt;/center&gt;

&lt;p&gt;which, when integrated, simplifies to,&lt;/p&gt;

&lt;center&gt;
$$\Omega = -\frac{16}{15} G \pi^{2} \rho^{2} R^{5}$$
&lt;/center&gt;

&lt;p&gt;This can be rewritten in terms of the mass of the Sun, $M = \frac{4}{3} \pi r^{3} \rho$, as&lt;/p&gt;

&lt;center&gt;
$$\Omega = -\frac{3M^{2}G}{5R}$$
&lt;/center&gt;

&lt;p&gt;So, we now have a value for the total gravitational potential energy of our Sun. But before using this to calculate its age, we need to invoke a new theorem. Kelvin’s argument relies on the fact that the Sun is radiating energy that comes from gravtitational contraction. The form in which this energy arises within the stars is thermal, through heating. The conversion of gravitational potential energy to thermal energy is not 1:1, but is in fact related by the &lt;em&gt;Virial theorem&lt;/em&gt;, which states that the total gravitational potential energy of a body, $\Omega$, is equal to minus two times the internal &lt;em&gt;thermal&lt;/em&gt; energy of the body,&lt;/p&gt;

&lt;center&gt;
$$\Omega = -2U$$
&lt;/center&gt;

&lt;p&gt;So, only half of the total gravitational potential energy can be converted to thermal energy. The minus sign in the above equation is important when explaining why bodies appear to get hotter as they contract and lose energy. In our case, the total thermal energy within the sun is then,&lt;/p&gt;

&lt;center&gt;
$$U = \frac{3M^{2}G}{10R}$$
&lt;/center&gt;

&lt;p&gt;We can now use this to calculate the age of the Sun! Given the luminosity of the Sun today ($L = 3.846 \times 10^{26}$ Watts), and assuming that this has stayed constant throughout the Sun’s life, the age can be given by the ratio of the total thermal energy against the rate of energy loss. Sticking everything in, we get&lt;/p&gt;

&lt;center&gt;
$$\frac{U}{L} = t_{eff} \approx 9 \ \mathrm{million \ years}$$
&lt;/center&gt;

&lt;p&gt;As we said previously, if we assume that the Earth formed after or concurrently with the Sun, then the Earth must be younger than this. This result contradicted those that believed the Earth had been around forever, and was one of the unsung successes of the theory today. Unfortunately, it is the value of the age itself that has become infamous.&lt;/p&gt;

&lt;p&gt;In short, this age is nowhere near long enough; Geologists such as Charles Lyell had argued that the processes that shaped the Earth’s surface, such as erosion and uplift, required far greater timescales. In biology, Charles Darwin’s natural selection also required far greater timescales on which to act to account for the variety of species existing today.&lt;/p&gt;

&lt;p&gt;Unhelpfully, rather than exploring these issues, Kelvin simply refused to accept them, and continued to argue that gravitational contraction could be the only source of the Sun’s energy, and therefore that the age of the Sun must of order millions of years, not billions. He called some of Darwin’s estimates ‘absurd’, and used Physics position as a more established and prestigious field than Geology (at the time) to bully its purveyors. This went on for nearly 50 years.&lt;/p&gt;

&lt;p&gt;It took the discovery of radioactivity as an alternative heat source, both for the Earth and the Sun, to render Kelvin’s assumptions invalid and eventually rubbish his theory. There was now a far larger energy source available to power the Sun for the timescales required by Biologists and Geologists. In terms of the age of the Earth, plate tectonics and convection in the Earth’s mantle, in addition to further heating from radioactive materials, placed much greater lower bounds on the Earth’s age.&lt;/p&gt;

&lt;p&gt;Radiometric dating of rocks also provided ‘bonus’ evidence, as rocks could now be shown to be far older than Kelvins initial results. Ernest Rutherford, a pioneer in radiometric dating, reveals a humourous encounter with Kelvin where he presented his early calculations:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;I came into the room, which was half dark, and presently spotted Lord Kelvin in the audience and realized that I was in trouble at the last part of my speech dealing with the age of the Earth, where my views conflicted with his. To my relief, Kelvin fell fast asleep, but as I came to the important point, I saw the old bird sit up, open an eye, and cock a baleful glance at me! Then a sudden inspiration came, and I said, ‘Lord Kelvin had limited the age of the Earth, provided no new source was discovered. That prophetic utterance refers to what we are now considering tonight, radium!’ Behold! the old boy beamed upon me.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Lessons learnt:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Don’t rely on your assumptions too much; even if your theory is simple and elegant; as the old adage goes, ‘rubbish in, rubbish out’.&lt;/li&gt;
  &lt;li&gt;Don’t be arrogant and pompous; even if you are the first British scientists to join the house of lords, if your model is wrong you’ll end up with egg on your face. And in the end, &lt;a href=&quot;https://en.wikipedia.org/wiki/George_E._P._Box&quot; target=&quot;blank&quot;&gt;all models are wrong, but some are useful&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;em&gt;Edit: the previous version of this post had the wrong sign for the thermal energy and &lt;strong&gt;all&lt;/strong&gt; the grammar mistakes, thanks to Abi and Spyros for pointing them out&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 13 Dec 2015 00:00:00 +0000</pubDate>
        <link>/2015/12/13/The-age-of-the-earth.html</link>
        <guid isPermaLink="true">/2015/12/13/The-age-of-the-earth.html</guid>
        
        <category>History</category>
        
        <category>Physics</category>
        
        
      </item>
    
      <item>
        <title>GCHQ Christmas Puzzle</title>
        <description>&lt;p&gt;The director of everyone’s favourite morally dubious crytographic government agency, GCHQ, has released a little &lt;a href=&quot;http://www.gchq.gov.uk/press_and_media/news_and_features/Pages/Directors-Christmas-puzzle-2015.aspx&quot; target=&quot;source&quot;&gt;brain teaser&lt;/a&gt; along with his Christmas card this year. I assume this is a means of keeping you preoccupied for at least 5 minutes over the holiday season whilst they read through your emails.&lt;/p&gt;

&lt;p&gt;I’ve solved the first part, which cleverly leads on to the next part of the puzzle. If you want to have a go, the grid and instructions are shown below. If you’re lazy, you can just click the image to link to the solved version, but if you’re lazy, you probably don’t care.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;In this type of grid-shading puzzle, each square is either black or white. Some of the black squares have already been filled in for you.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Each row or column is labelled with a string of numbers. The numbers indicate the length of all consecutive runs of black squares, and are displayed in the order that the runs appear in that line. For example, a label “2 1 6” indicates sets of two, one and six black squares, each of which will have at least one white square separating them.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;/images/grid-shading-puzzle-solved.jpg&quot; target=&quot;blank&quot;&gt;
  &lt;img src=&quot;/images/grid-shading-puzzle.jpg&quot; title=&quot;Nonogram&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 13 Dec 2015 00:00:00 +0000</pubDate>
        <link>/2015/12/13/GCHQ-christmas-puzzle.html</link>
        <guid isPermaLink="true">/2015/12/13/GCHQ-christmas-puzzle.html</guid>
        
        <category>Miscellany</category>
        
        
      </item>
    
      <item>
        <title>Orwell&#39;s support for the Rising</title>
        <description>&lt;p&gt;I’m currently reading &lt;a href=&quot;https://www.goodreads.com/book/show/1434257.Rising_44&quot;&gt;Rising ‘44&lt;/a&gt;, a book by &lt;a href=&quot;https://www.goodreads.com/author/show/22827.Norman_Davies&quot;&gt;Norman Davies&lt;/a&gt; which covers the terrible events in the polish capital of Warsaw in the penultimate year of World War II. It’s a brilliant book by one of my favourite authors, on a subject he evidently cares deeply about - he’s a Pola-phile who studied at Krakow, and wrote the definitive english language history of Poland, &lt;em&gt;God’s Playground&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;For those that don’t know, the Warsaw rising was a calamitous battle instigated by the Polish underground home army against their Nazi occupiers. The capital had been occupied for 5 years, and as the Soviets pushed the German lines back from the east, the insurgents saw the chance to retake their city for themselves. They expected that within days the capital could be taken, with support from their Soviet and Western allies, and so begin the liberation of the whole of Poland back to its pre-war borders.&lt;/p&gt;

&lt;p&gt;Instead, the battle lasted 63 days (longer than the siege of Stalingrad), with effectively no support from the Soviets, and meager airdrops from British bases in Italy. The resistance army was pitifully armed, but managed to hold its own against the far stronger Wehrmacht forces. More than 150,000-200,000 civilians perished, mostly from retaliatory mass executions performed by the Nazi’s, and the entire city was demolished.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/warsaw3.jpg&quot; data-lightbox=&quot;lightbox-image&quot; data-title=&quot;Complete destruction; only piles of rubble remain. Reminiscent of recent images from Syria.&quot;&gt;
  &lt;img src=&quot;/images/warsaw3.jpg&quot; title=&quot;Complete destruction; only piles of rubble remain. Reminiscent of recent images from Syria.&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Complete destruction; only piles of rubble remain. Reminiscent of recent images from Syria.&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Apportioning blame for this atrocity is difficult; you could say that the timing of the insurrection was poor, or that preparations were insufficient, or simply that the Varsovians were unlucky, victims of a series of calamitous decisions and events. But one cause, still controversial now, was being raised at all levels (even Churchill was suspicious) - Soviet stalling.&lt;/p&gt;

&lt;p&gt;At the time of the rising, Eric Blair, also known by his alias &lt;strong&gt;George Orwell&lt;/strong&gt;, was writing what would become Animal Farm, his allegorical fable on Soviet style totalitarianism. He was also literary editor of the socialist journal the &lt;em&gt;Tribune&lt;/em&gt;, and wrote between 1943-1944 on all manner of political topics.&lt;/p&gt;

&lt;p&gt;The article below was published on the 1st of September, 1944, 6 weeks in to the battle. It was aimed to counter the arguments of an article that appeared in the previous week criticising the rising, but also as a general criticism of the unwavering support for Moscow shown by the British press. As literary takedowns go, it is one of the best; a principled stand for reason against the disinformation and dishonesty of the British &lt;em&gt;intelligentsia&lt;/em&gt; of the time, oblivious to the execution of one of the great injustices of the twentieth century. I thought it was brilliant.&lt;/p&gt;

&lt;p&gt;I heartedly recommend reading the book, as I do anything by Norman Davies, but if you don’t have time for a 700 page door stop and still want to learn more about the Rising then &lt;a href=&quot;http://www.warsawrising.eu/&quot;&gt;this site&lt;/a&gt; has a great interactive overview.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/eastern_front.png&quot; data-lightbox=&quot;lightbox-image&quot; data-title=&quot;Soviet advances on the eastern front, with suspiciously little progress past Warsaw during the rising.&quot;&gt;
  &lt;img src=&quot;/images/eastern_front.png&quot; title=&quot;Soviet advances on the eastern front, with suspiciously little progress past Warsaw during the rising.&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Soviet advances on the eastern front, with suspiciously little progress past Warsaw during the rising.&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt; The Recent Rising in Warsaw &lt;/h3&gt;

&lt;p&gt;It is not my primary job to discuss the details of contemporary politics, but this week there is something that cries out to be said.  Since, it seems, nobody else will do so, I want to protest against the mean and cowardly attitude adopted by the British press towards the recent rising in Warsaw.&lt;/p&gt;

&lt;p&gt;As soon as the news of the rising broke, the News Chronicle and kindred papers adopted a markedly disapproving attitude.  One was left with the general impression that the Poles deserved to have their bottoms smacked for doing what all the Allied wirelesses had been urging them to do for years past, and that they would not be given and did not deserve to be given any help from outside.  A few papers tentatively suggested that arms and supplies might be dropped by the Anglo-Americans, a thousand miles away: no one, so far as I know, suggested that this might be done by the Russians, perhaps twenty miles away.  The New Statesman, in its issue of 18 August, even went so far as to doubt whether appreciable help could be given from the air in such circumstances.  All or nearly all the papers of the Left were full of blame for the émigré London Government which had ‘prematurely’ ordered its followers to rise when the Red army was at the gates.  This line of thought is adequately set forth in a letter to last week’s Tribune from Mr G. Barraclough.  He makes the following speciﬁc charges:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;The Warsaw rising was ‘not a spontaneous popular rising’, but was ‘begun on orders from the soi-disant Polish Government in London’.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The order to rise was given ‘without consultation with either the British or Soviet Governments’, and ‘no attempt was made to co-ordinate the rising with Allied action’.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Polish resistance movement is no more united round the London Government than the Greek resistance movement is united round King George of the Hellenes.  (This is further emphasized by frequent use of the words émigré, soi-disant, etc., applied to the London Government.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The London Government precipitated the rising in order to be in possession of Warsaw when the Russians arrived, because in that case ‘the bargaining position of the émigré Government would be improved’.  The London Government, we are told, ‘is ready to betray the Polish people’s cause to bolster up its own tenure of precarious ofﬁce’, with much more to the same effect.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;No shadow of proof is offered for any of these charges, though 1 and 2 are of a kind that could be veriﬁed and may well be true.  My own guess is that 2 is true and 1 partly true.  The third charge makes nonsense of the ﬁrst two.  If the London Government is not accepted by the mass of the people in Warsaw, why should they raise a desperate insurrection on its orders?  By blaming Sosnkowski and the rest for the rising, you are automatically assuming that it is to them that the Polish people looks for guidance.  This obvious contradiction has been repeated in paper after paper, without, so far as I know, a single person having the honesty to point it out.  As for the use of such expressions as émigré, it is simply a rhetorical trick.  If the London Poles are migr s, so are the Polish National Committee of Liberation, besides the ‘free’ Governments of all the occupied countries.  Why does one become an émigré by emigrating to London and not by emigrating to Moscow?&lt;/p&gt;

&lt;p&gt;Charge No. 4 is morally on a par with the Osservatore Romano’s suggestion that the Russians held up their attack on Warsaw in order to get as many Polish resisters as possible killed off.  It is the unproved and unprovable assertion of a mere propagandist who has no wish to establish the truth, but is simply out to do as much dirt on his opponent as possible.  And all that I have read about this matter in the press—except for some very obscure papers and some remarks in Tribune, the Economist and the Evening Standard—is on the same level as Mr Barraclough’s letter.&lt;/p&gt;

&lt;p&gt;Now, I know nothing of Polish affairs, and even if I had the power to do so I would not intervene in the struggle between the London Polish Government and the Moscow National Committee of Liberation.  What I am concerned with is the attitude of the British intelligentsia, who cannot raise between them one single voice to question what they believe to be Russian policy, no matter what turn it takes, and in this case have had the unheard-of meanness to hint that our bombers ought not to be sent to the aid of our comrades ﬁghting in Warsaw.  The enormous majority of left-wingers who swallow the policy put out by the News Chronicle, etc., know no more about Poland than I do.  All they know is that the Russians object to the London Government and have set up a rival organization, and so far as they are concerned that settles the matter.  If tomorrow Stalin were to drop the Committee of Liberation and recognize the London Government, the whole British intelligentsia would ﬂock after him like a troop of parrots.  Their attitude towards Russian foreign policy is not ‘Is this policy right or wrong?’ but ‘This is Russian policy: how can we make it appear right?’  And this attitude is defended, if at all, solely on grounds of power.&lt;/p&gt;

&lt;p&gt;The Russians are powerful in eastern Europe, we are not: therefore we must not oppose them.  This involves the principle, of its nature alien to Socialism, that you must not protest against an evil which you cannot prevent.&lt;/p&gt;

&lt;p&gt;I cannot discuss here why it is that the British intelligentsia, with few exceptions, have developed a nationalistic loyalty towards the U.S.S.R. and are dishonestly uncritical of its policies.  In any case, I have discussed it elsewhere.  But I would like to close with two considerations which are worth thinking over.&lt;/p&gt;

&lt;p&gt;First of all, a message to English left-wing journalists and intellectuals generally:  ‘Do remember that dishonesty and cowardice always have to be paid for.  Don’t imagine that for years on end you can make yourself the boot-licking propagandist of the Soviet régime, or any other régime, and then suddenly return to mental decency.  Once a whore, always a whore.’&lt;/p&gt;

&lt;p&gt;Secondly, a wider consideration.  Nothing is more important in the world today than Anglo-Russian friendship and co-operation, and that will not be attained without plain speaking.  The best way to come to an agreement with a foreign nation is not to refrain from criticizing its policies, even to the extent of leaving your own people in the dark about them.  At present, so slavish is the attitude of nearly the whole British press that ordinary people have very little idea of what is happening, and may well be committed to policies which they will repudiate in ﬁve years’ time.  In a shadowy sort of way we have been told that the Russian peace terms are a super-Versailles, with partition of Germany, astronomical reparations, and forced labour on a huge scale.  These proposals go practically uncriticized, while in much of the left-wing press hack writers are even hired to extol them.  The result is that the average man has no notion of the enormity of what is proposed.  I don’t know whether, when the time comes, the Russians will really want to put such terms into operation.  My guess is that they won’t.  But what I do know is that if any such thing were done, the British and probably the American public would never support it when the passion of war had died down.  Any ﬂagrantly unjust peace settlement will simply have the result, as it did last time, of making the British people unreasonably sympathetic with the victims.  Anglo-Russian friendship depends upon there being a policy which both countries can agree upon, and this is impossible without free discussion and genuine criticism now.  There can be no real alliance on the basis of ‘Stalin is always right’.  The ﬁrst step towards a real alliance is the dropping of illusions.&lt;/p&gt;

&lt;p&gt;Finally, a word to the people who will write me letters about this.  May I once again draw attention to the title of this column and remind everyone that the Editors of Tribune are not necessarily in agreement with all that I say, but are putting into practice their belief in freedom of speech?&lt;/p&gt;

&lt;h3 id=&quot;george-orwell&quot;&gt;George Orwell&lt;/h3&gt;

&lt;hr /&gt;
</description>
        <pubDate>Sun, 15 Nov 2015 00:00:00 +0000</pubDate>
        <link>/2015/11/15/orwell-warsaw.html</link>
        <guid isPermaLink="true">/2015/11/15/orwell-warsaw.html</guid>
        
        <category>History</category>
        
        
      </item>
    
      <item>
        <title>Classifying Astronomical Data Using Tree Based Methods</title>
        <description>&lt;p&gt;The following is a guide to using tree based methods in R, based on the corresponding chapter in ‘An Introduction to Statistical Learning’ but using data from the &lt;strong&gt;Sloan Digital Sky Survey&lt;/strong&gt; (SDSS). The aim is to use the five colour bands provided by the SDSS extract, &lt;em&gt;u&lt;/em&gt; (ultraviolet), &lt;em&gt;g&lt;/em&gt; (green), &lt;em&gt;r&lt;/em&gt; (red), &lt;em&gt;i&lt;/em&gt; &amp;amp; &lt;em&gt;z&lt;/em&gt; (very-near-infrared), to predict whether the sources in the survey are Quasars, Stars or White Dwarfs. I use a variety of techniques, from simple decision trees to ensemble methods such as random forests.&lt;/p&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;

&lt;p&gt;Rather than getting the data directly from SDSS and doing the cleaning myself, I’m going to cheat and use a pre-filtered data set used in the book ‘Modern Statistical Methods for Astronomy’, available &lt;a href=&quot;http://astrostatistics.psu.edu/MSMA/datasets/index.html&quot;&gt;here&lt;/a&gt;. As part of their extract they perform a few cleaning operations, such as ignoring spatially resolved galaxies, those with large measurement errors, and those that are very bright (and could cause saturation) or very faint (with uncertain measurements). They also provide 3 labelled data sets for training, one each for Quasars, Stars &amp;amp; White Dwarfs.&lt;/p&gt;

&lt;p&gt;The colour bands as they stand aren’t particularly useful, since objects of the same class can be at different distances, and therefore have relatively lower flux across all bands. This can be avoided by looking at the ratios of brightness across bands, and since magnitudes are logarithmic units of brightness we simply find the difference between the provided values to get four colour indices, &lt;em&gt;(u-g)&lt;/em&gt;, &lt;em&gt;(g-r)&lt;/em&gt;, &lt;em&gt;(r-i)&lt;/em&gt; &amp;amp; &lt;em&gt;(i-z)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The following three code chunks extract and clean the training data for all three sources and combine them in to a single data frame. Quasras, stars and white dwarfs are given the labels 1,2 and 3 respectively. There are 5000 stellar objects available for training, but for quasars there are over 7.7429 × 10&lt;sup&gt;4&lt;/sup&gt; and for white dwarfs over 1.009 × 10&lt;sup&gt;4&lt;/sup&gt;, so I’ve filtered each of the latter two down to only 5000 so that there are equal numbers of each class.&lt;/p&gt;

&lt;p&gt;Quasar training set (Class 1):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;http://astrostatistics.psu.edu/MSMA/datasets/SDSS_QSO.dat&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;bad_phot_qso&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;which&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;21.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bad_phot_qso&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;qso_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qso_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;u_g&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;g_r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;r_i&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;i_z&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Class&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Star training set (Class 2):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;http://astrostatistics.psu.edu/MSMA/datasets/SDSS_stars.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;star_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;star_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;u_g&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;g_r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;r_i&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;i_z&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Class&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;White dwarf training set (Class 3):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;http://astrostatistics.psu.edu/MSMA/datasets/SDSS_wd.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;na.omit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;wd_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wd_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;u_g&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;g_r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;r_i&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;i_z&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Class&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Combine the training sets&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qso_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;u_g&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;g_r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;r_i&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;i_z&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Class&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## &#39;data.frame&#39;:	15000 obs. of  5 variables:
##  $ u_g  : num  -0.079 0.033 0.11 0.325 0.22 ...
##  $ g_r  : num  0.136 0.255 0.425 0.448 0.049 ...
##  $ r_i  : num  0.233 0.454 0.221 0.114 0.189 ...
##  $ i_z  : num  0.046 0.3 -0.158 0.221 0.04 ...
##  $ Class: num  1 1 1 1 1 1 1 1 1 1 ...&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The plot below shows each training class on a bivariate colour-colour scatter plot.There’s plenty of structure to each class, something that tree based methods should be more than capable of picking up on.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-5-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;decision-trees&quot;&gt;Decision Trees&lt;/h2&gt;

&lt;p&gt;Decision trees are the most basic tree based method, and one on which the majority of other methods are built on They work by splitting the predictor space in to regions; each split can be thought of as a &lt;em&gt;branch&lt;/em&gt;, and each of the remaining regions are &lt;em&gt;leaves&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The default &lt;code class=&quot;highlighter-rouge&quot;&gt;tree&lt;/code&gt; library has a simple binary recursive partitioning method for growing regression or classification trees.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Below we split the data in to a training and test set, and train the classifier on the training test.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as.factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tree.sdss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tree.sdss&lt;/code&gt; is our trained classifier. We can plot it to see the major branches and leaves of the tree. The default is pretty cluttered, so I’ve coloured and rotated the text to make it easier to read… not sure if that really helps. The &lt;code class=&quot;highlighter-rouge&quot;&gt;rpart&lt;/code&gt; package for building trees has some nicer plotting capabilities but, in the spirit of every undergraduate lab report, ‘&lt;em&gt;that is beyond the purposes of this investigation&lt;/em&gt;’.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rainbow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-8-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To evaluate our tree, we use it to predict the class of our test data.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;tree.pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Below is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;confusion matrix&lt;/a&gt; of the predicted classes against the actual.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##
## tree.pred   1   2   3
##         1 921   8 131
##         2  65 985   1
##         3  14   0 875&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The overall test error rate is 7.3%.&lt;/p&gt;

&lt;p&gt;Often the algorithm that builds the tree can create more branches than necessary, and end up reducing the predictive accuracy of our classifier. To test this I perform cross validation on the built tree. Specifying &lt;code class=&quot;highlighter-rouge&quot;&gt;FUN = prune.misclass&lt;/code&gt; tells &lt;code class=&quot;highlighter-rouge&quot;&gt;cv.tree&lt;/code&gt; that we want the cross validation to be guided by the classification error rate, rather than the default which is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Deviance_(statistics)&quot;&gt;deviance&lt;/a&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;cv.sdss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv.tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FUN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prune.misclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cv.sdss&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## $size
## [1] 11 10  9  7  6  5  3  2  1
##
## $dev
## [1]  868  868  922  971 1039 1194 1592 4050 8177
##
## $k
## [1]   -Inf    0.0   38.0   44.5   72.0  111.0  217.0 2482.0 3943.0
##
## $method
## [1] &quot;misclass&quot;
##
## attr(,&quot;class&quot;)
## [1] &quot;prune&quot;         &quot;tree.sequence&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The left hand plot shows the error rate against tree size, the right against the cost complexity parameter &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-12-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The 10 branch tree has the same error rate as the 11, so pruning to this size will not reduce the predictive power of the model, but will reduce the complexity.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;min_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv.sdss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;which&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv.sdss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv.sdss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# find minimum size that fits best
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prune.sdss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prune.misclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;par&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mfrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prune.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rainbow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-14-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;tree.pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prune.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test.results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree.pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test.results&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##
## tree.pred   1   2   3
##         1 921   8 131
##         2  65 985   1
##         3  14   0 875&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The error rate, 7.3%, is the same, as expected, but the tree is easier to interpret.&lt;/p&gt;

&lt;h2 id=&quot;bagging-and-random-forests&quot;&gt;Bagging and Random Forests&lt;/h2&gt;

&lt;p&gt;Bagging and random forests are both examples of ensemble methods, where many decison trees are combined together to improve the prediction accuracy. Both can be implemented using the &lt;code class=&quot;highlighter-rouge&quot;&gt;randomForest&lt;/code&gt; package.&lt;/p&gt;

&lt;p&gt;Bagging (derived from the full name &lt;em&gt;Bootstrap Aggregation&lt;/em&gt;) takes multiple bootstrapped samples from the same training set and builds an ensemble of trees that are then averaged. Bagging uses all predictors; &lt;code class=&quot;highlighter-rouge&quot;&gt;mtry&lt;/code&gt; states that all 4 predictors should be considered for each split of the tree.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randomForest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;bag.sdss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randomForest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mtry&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;importance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bag.sdss&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##
## Call:
##  randomForest(formula = Class ~ ., data = SDSS_train, mtry = 4,      importance = T, subset = train)
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 4
##
##         OOB estimate of  error rate: 2.38%
## Confusion matrix:
##      1    2    3 class.error
## 1 3853   55   92 0.036750000
## 2   25 3981    1 0.006488645
## 3  111    1 3881 0.028049086&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;yhat.bag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bag.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newdata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##
## yhat.bag   1   2   3
##        1 966   5  36
##        2  12 988   0
##        3  22   0 971&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The test error rate associated with the bagged tree is 2.5%, a significant improvement over the single decision tree.&lt;/p&gt;

&lt;p&gt;Random forests are similar to bagged trees, but with a small tweak to the algorithm; at each step, when a split is considered only a &lt;em&gt;random subset&lt;/em&gt; of the predictors is made available. This prevents strong features from dominating the root branches of the trees, otherwise this can lead to correlations between the predictions of the trees, as they all look relatively similar. The trees in a random forest ensemble can be thought of as &lt;em&gt;decorrelated&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Growing a random forest proceeds in the same way as Bagging, but with a smaller value for &lt;code class=&quot;highlighter-rouge&quot;&gt;mtry&lt;/code&gt;. By default, for classification problems &lt;code class=&quot;highlighter-rouge&quot;&gt;randomForst&lt;/code&gt; uses $\sqrt{p}$ predictors, so 2 in our case.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;rf.sdss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randomForest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;importance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rf.sdss&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##
## Call:
##  randomForest(formula = Class ~ ., data = SDSS_train, importance = T,      subset = train)
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
##
##         OOB estimate of  error rate: 2.17%
## Confusion matrix:
##      1    2    3 class.error
## 1 3869   50   81 0.032750000
## 2   23 3983    1 0.005989518
## 3  104    2 3887 0.026546456&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;yhat.rf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rf.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newdata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test.results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yhat.rf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The test error rate associated with the random forest is 2.37%, a further improvement over the bagged tree.&lt;/p&gt;

&lt;p&gt;We can use the &lt;code class=&quot;highlighter-rouge&quot;&gt;importance&lt;/code&gt; function to view the importance of each of the variables used as our features. The first, &lt;code class=&quot;highlighter-rouge&quot;&gt;%IncMSE&lt;/code&gt;, measures the mean decrease in accuracy of the predictions on out of bag samples when that feature is excluded from the model. The second, &lt;code class=&quot;highlighter-rouge&quot;&gt;IncNodePurity&lt;/code&gt;, measures the decrease in node impurity due to splits over that variable, over all trees; node impurity measured by training RSS in the case of regression trees, and deviance for classification trees. &lt;code class=&quot;highlighter-rouge&quot;&gt;varImpPlot&lt;/code&gt; plots these importance functions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-22-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;boosting&quot;&gt;Boosting&lt;/h2&gt;

&lt;p&gt;Boosting algortihms for regression and classification problems are different, and I will not provide a full description here (for details, see &lt;a href=&quot;https://www.statsoft.com/Textbook/Boosting-Trees-Regression-Classification/button/1&quot;&gt;here&lt;/a&gt;). In basic terms, boosting algorithms apply many weak learners sequentially to the residuals (i.e. the remaining unexplained data) of previous trees. The algorithm learns slowly and incrementally, which can lead to a better resulting model, at the cost of extra computation compared to more direct learners.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;gbm&lt;/code&gt; function, from the identically named package, is used here to perform Boosting.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;boost.sdss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gbm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distribution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;multinomial&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n.trees&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interaction.depth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boost.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-26-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##     var   rel.inf
## u_g u_g 46.908265
## g_r g_r 23.571429
## r_i r_i 22.557859
## i_z i_z  6.962446&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The plot above shows the relative importance of each feature in the training data. The &lt;code class=&quot;highlighter-rouge&quot;&gt;interaction.depth&lt;/code&gt; argument, in the cal to &lt;code class=&quot;highlighter-rouge&quot;&gt;gbm&lt;/code&gt;, limits the depth of each tree. Here we use a multinomial distribution as this is a multinomial classification problem; if it was binary, use a bernoulli distribution, or if performing a regression, use a gaussian distribution.&lt;/p&gt;

&lt;p&gt;Below are some &lt;em&gt;partial dependence plots&lt;/em&gt;, which integrate out other variables to show the marginal effect of selected variables. The black line shows class 1, the red line class 2, and green class 3 (Quasars, Stars &amp;amp; White Dwarfs respectively). The peaks of each line show where for this line ratio that particular class can be identified most clearly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-27-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;yhat.boost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boost.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newdata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n.trees&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;response&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;yhat.boost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yhat.boost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;which.max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictor&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##
## yhat.boost   1   2   3
##          1 953   3  47
##          2  28 990   0
##          3  19   0 960&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Test error rate associated with Boosting is 3.23%. This is actually &lt;strong&gt;worse&lt;/strong&gt; than the bagging and random forest approaches above, for this particular data set, and the performance is $~\mathcal{O}(10)$ worse.&lt;/p&gt;

&lt;h2 id=&quot;extremely-randomized-trees&quot;&gt;Extremely randomized trees&lt;/h2&gt;

&lt;p&gt;Extremely Randomised Trees (ERTs) are a relatively modern incarnation of random forests. The difference is that, after choosing a random subset of features, the threshold for the split on each feature is also chosen randomly, and the best split is then chosen. Then ensemble of trees is again combined to provide the best estimate. This randomness increases the variance at the cost of a little bias.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;extraTrees&lt;/code&gt; package in R can execute ERTs. Somme of the documentation looks a little rough around the edges, so I’d certainly take a closer look at the source code if you’re doing anything important with it. For our purposes though it will suffice.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extraTrees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;et&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extraTrees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;yhat.et&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;et&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##
## yhat.et   1   2   3
##       1 972   3  35
##       2  12 990   0
##       3  16   0 972&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Test error rate associated with ERTs is 2.2%, the best of all the approaches demonstrated here.&lt;/p&gt;

&lt;h2 id=&quot;sdss-test-data&quot;&gt;SDSS ‘test’ data&lt;/h2&gt;

&lt;p&gt;The source of the data used in this post, the textbook ‘&lt;a href=&quot;http://astrostatistics.psu.edu/MSMA/datasets/index.html&quot;&gt;Modern Statistical Methods for Astronomy&lt;/a&gt;’, made another set of SDSS data available named ‘test data’ that consist of 17000 sources. Unfortunately it doesn’t have any associated source classes, making it a pretty useless test set! However, it is useful to apply our models to and analyse from inspection. Here I use the random forest model, since it has one of the best error rate to complexity ratios. Below is a colour-colour plot similar to that made at the start of the workbook for the training data (repeated below for easier comparison).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SDSS point sources test dataset, N=17,000 (mag&amp;lt;21, point sources, hi-qual)&lt;/em&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;http://astrostatistics.psu.edu/MSMA/datasets/SDSS_test.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SDSS_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;u_g&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;g_r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;r_i&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;i_z&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;SDSS_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class.Predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rf.sdss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SDSS_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#yhat.boost &amp;lt;- predict(boost.sdss, SDSS_test, n.trees = 5000, type=&#39;response&#39;)
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SDSS_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class.Predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yhat.boost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;which.max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictor&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-35-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../images/SDSS_decision_trees/unnamed-chunk-36-1.png&quot; title=&quot;center&quot; alt=&quot;center&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are a few interesting features here. Firstly, there are hardly any white dwarfs identified. This could be because there aren’t very many in this data set, or the algorithm is failing to pick up on them. In the &lt;em&gt;u-g&lt;/em&gt;/&lt;em&gt;g-r&lt;/em&gt; plot on the left hand side their is also a clear vertical boundary on the red stellar classification. This lines up exactly with where the stars with lowest &lt;em&gt;u-g&lt;/em&gt; line ratio lie in the training set, suggesting that our model isn’t able to classify stars beyind this range.&lt;/p&gt;

&lt;p&gt;Given that we don’t know what is actually in the ‘test’ data set, it’s hard to draw any firm conclusions from it, but it does highlight some of the limitations of such learning algorithms, namely that they are very bad at predicting events beyond what they’ve been trained to; this is more generally known as ‘overfitting’, in relation to the training set.&lt;/p&gt;

&lt;p&gt;All of the code used to produce this post is available &lt;a href=&quot;https://github.com/polyphant1/statistical_learning/blob/master/SDSS_decision_trees.Rmd&quot;&gt;here&lt;/a&gt;. Thanks for reading.&lt;/p&gt;
</description>
        <pubDate>Sat, 14 Nov 2015 00:00:00 +0000</pubDate>
        <link>/2015/11/14/sdss-decision-trees.html</link>
        <guid isPermaLink="true">/2015/11/14/sdss-decision-trees.html</guid>
        
        <category>Data Science</category>
        
        <category>Physics</category>
        
        
      </item>
    
      <item>
        <title>Avoiding tailored ads in the EU</title>
        <description>&lt;p&gt;Found a great site today that everyone should know about - &lt;a href=&quot;http://youronlinechoices.com/uk/&quot; target=&quot;_blank&quot;&gt;youronlinechoices.com&lt;/a&gt;. It gives you the power to tell companies that you don’t want to receive targeted advertising online. It’s a result of some &lt;a href=&quot;http://www.youronlinechoices.com/goodpractice&quot; target=&quot;_blank&quot;&gt;obscure EU guidelines&lt;/a&gt; dating back to 2011 for “for businesses collecting and using online information for behavioural advertising”, and there are some big names signed up: Amazon, Microsoft, Facebook and Google are all listed, and you’re free to ‘tell them where to go’, so to speak. I’m assuming it uses cookies to match your current browsing session with company data, which is a neat approach.&lt;/p&gt;

&lt;p&gt;Whilst I’m not totally opposed to this kind of data driven advertising, it should certainly be partnered with greater consumer control, and transparency on the exact data that companies are collecting. This is a small but worthwhile step in the right direction… but why has it not been popularised more widely? Have I really just missed this resource by chance?&lt;/p&gt;

&lt;p&gt;P.S. I’ve only discovered and activated this today. I’ll keep an eye on advertisements from a few of the companies I disabled and report back if I find any trickery. If you try it, let me know how you get on; If you’re also having problems, you can report it officially &lt;a href=&quot;http://www.youronlinechoices.com/uk/make-a-complaint&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 02 Nov 2015 00:00:00 +0000</pubDate>
        <link>/2015/11/02/ad-tracking-preferences.html</link>
        <guid isPermaLink="true">/2015/11/02/ad-tracking-preferences.html</guid>
        
        <category>Technology</category>
        
        
      </item>
    
      <item>
        <title>m3u to JSON</title>
        <description>&lt;p&gt;I have tens of playlists from my pre-spotify days locked inside my old mediamonkey installation that I’d quite like to liberate (I have grand plans to publish them here some day), but they’re all in a horrible format called m3u. JSON is much prettier, so I wrote an R script that converts m3u to JSON. Some of the Regex isn’t pretty, but it works.&lt;/p&gt;

&lt;noscript&gt;&lt;pre&gt;400: Invalid request
&lt;/pre&gt;&lt;/noscript&gt;
&lt;script src=&quot;https://gist.github.com/9db2bdd81088cf673219.js&quot;&gt; &lt;/script&gt;

</description>
        <pubDate>Sun, 01 Nov 2015 00:00:00 +0000</pubDate>
        <link>/2015/11/01/m3u-to-json.html</link>
        <guid isPermaLink="true">/2015/11/01/m3u-to-json.html</guid>
        
        <category>Technology</category>
        
        
      </item>
    
      <item>
        <title>Blog now sporting a new winter coat with tags</title>
        <description>&lt;p&gt;Just finished updating the blog with a couple of new features. The main one is tags for posts, based on &lt;a href=&quot;http://christianspecht.de/2014/10/25/separate-pages-per-tag-category-with-jekyll-without-plugins/&quot; target=&quot;_blank&quot;&gt;this guide&lt;/a&gt; by Christian Specht. Because Jekyll is a static site generator it can be difficult to generate dynamic pages such as tag pages on the fly. The solution I used here is half way there - I still have to create a new tag page each time I define a new tag. &lt;a href=&quot;http://charliepark.org/tags-in-jekyll/&quot; target=&quot;_blank&quot;&gt;This solution&lt;/a&gt; from Charlie Park looks neat, but the plugin didn’t compile for me. I also convinced myself that I could add more detail to each tag page if I wanted to in its current state… which I may do at some point. Maybe.&lt;/p&gt;

&lt;p&gt;Whilst adding the navigation bar for the new tag pages I started playing around with some of the CSS, which quickly descended in to a complete redesign. It’s a lot more minimal (boring) now, and should be easier to use.&lt;/p&gt;

&lt;p&gt;Go forth and find bugs.&lt;/p&gt;
</description>
        <pubDate>Mon, 26 Oct 2015 00:00:00 +0000</pubDate>
        <link>/2015/10/26/site-update.html</link>
        <guid isPermaLink="true">/2015/10/26/site-update.html</guid>
        
        <category>Meta</category>
        
        
      </item>
    
  </channel>
</rss>
